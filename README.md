The primary goal of toxic comment classification is to develop a model that can predict whether a given text comment falls into one or more predefined categories of toxicity, such as “toxic", “obscene", “insult", “severe_toxic", “identity_hate", or “threat".
